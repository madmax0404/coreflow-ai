{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6e9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b159f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = os.getenv(\"ollama_url\")\n",
    "ollama_model = os.getenv(\"ollama_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740e2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    base_url = ollama_url + 'v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7705cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49ce91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series was played in **Boston**! Specifically, it was held at Fenway Park, though it was played in empty stadiums due to the COVID-19 pandemic.\n"
     ]
    }
   ],
   "source": [
    "response = llm.chat.completions.create(\n",
    "  model=ollama_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b642e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool() -> None:\n",
    "    \"\"\"Testing tool.\"\"\"\n",
    "    ...\n",
    "    \n",
    "def pre_model_hook() -> None:\n",
    "    \"\"\"Pre-model hook.\"\"\"\n",
    "    ...\n",
    "    \n",
    "def post_model_hook() -> None:\n",
    "    \"\"\"Post-model hook.\"\"\"\n",
    "    ...\n",
    "    \n",
    "class ResponseFormat(BaseModel):\n",
    "    \"\"\"Response format for the agent.\"\"\"\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4197e0dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'bind_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m agent = \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_model_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_model_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpost_model_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_model_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponseFormat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\FinalProjectAIWorkspace\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:534\u001b[39m, in \u001b[36mcreate_react_agent\u001b[39m\u001b[34m(model, tools, prompt, response_format, pre_model_hook, post_model_hook, state_schema, context_schema, checkpointer, store, interrupt_before, interrupt_after, debug, version, name, **deprecated_kwargs)\u001b[39m\n\u001b[32m    528\u001b[39m         model = cast(BaseChatModel, init_chat_model(model))\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    531\u001b[39m         _should_bind_tools(model, tool_classes, num_builtin=\u001b[38;5;28mlen\u001b[39m(llm_builtin_tools))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    532\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_classes + llm_builtin_tools) > \u001b[32m0\u001b[39m\n\u001b[32m    533\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m         model = \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m(\n\u001b[32m    535\u001b[39m             tool_classes + llm_builtin_tools  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m    536\u001b[39m         )\n\u001b[32m    538\u001b[39m     static_model: Optional[Runnable] = _get_prompt_runnable(prompt) | model  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    540\u001b[39m     \u001b[38;5;66;03m# For dynamic models, we'll create the runnable at runtime\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'OpenAI' object has no attribute 'bind_tools'"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[tool],\n",
    "    pre_model_hook=pre_model_hook,\n",
    "    post_model_hook=post_model_hook,\n",
    "    response_format=ResponseFormat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c654364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalProjectAIWorkspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
