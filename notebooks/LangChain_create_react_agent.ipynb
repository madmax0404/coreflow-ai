{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d75414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, uuid, sys, asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1f1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = os.getenv(\"ollama_url\")\n",
    "ollama_model = os.getenv(\"ollama_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740d8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=ollama_model,\n",
    "    base_url=ollama_url+\"v1\",\n",
    "    api_key=\"ollama\",\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8d90cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/FinalProjectAIWorkspace/notebooks')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = pathlib.Path.cwd()\n",
    "BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a97396f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/FinalProjectAIWorkspace/src/agents/mcp/server.py')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVER_PATH = (BASE_DIR / \"..\" / \"src\" / \"agents\" / \"mcp\" / \"server.py\").resolve()\n",
    "SERVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a8e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a700a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/FinalProjectAIWorkspace/src/agents/mcp/server.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(SERVER_PATH).replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad943095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/FinalProjectAIWorkspace/src/agents/mcp')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVER_PATH.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c255d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"RAG_and_weather\": {\n",
    "            \"transport\": \"stdio\",  # Local subprocess communication\n",
    "            \"command\": \"uv\",\n",
    "            # Absolute path to your math_server.py file\n",
    "            \"args\": [\"run\", \"python\", str(SERVER_PATH).replace(\"\\\\\", \"/\")],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34bcc642",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tools = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\asyncio\\runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "tools = asyncio.run(client.get_tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa8912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a75768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object MultiServerMCPClient.get_tools at 0x00000183F7455930>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c4957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b5c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ping(host: str) -> str:\n",
    "    \"\"\"Return 'pong' pretending to ping a host.\"\"\"\n",
    "    # 진짜 핑을 치려면 subprocess로 ping 실행하거나, requests로 healthcheck 등 구현\n",
    "    return f\"pong:{host}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ce709",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_user_age(name: str) -> str:\n",
    "    \"\"\"Use this tool to find the user's age.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    if \"bob\" in name.lower():\n",
    "        return \"42 years old\"\n",
    "    return \"41 years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/react-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, [ping, get_user_age], prompt=prompt)\n",
    "# agent = create_react_agent(llm, [ping, get_user_age], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f26910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18399835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor = AgentExecutor(agent=agent, tools=[ping, get_user_age], verbose=True, memory=memory)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[ping, get_user_age], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb18418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 저장소 (간단한 in-memory dict 예시)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "agent_with_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 아이디는 네가 정한다\n",
    "cfg = {\"configurable\": {\"session_id\": \"user-123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent_with_history.invoke({\"input\": \"hi! I'm bob. What is my age?\"}, config=cfg)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent_with_history.invoke({\"input\": \"do you remember my name?\"}, config=cfg)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinalProjectAIWorkspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
